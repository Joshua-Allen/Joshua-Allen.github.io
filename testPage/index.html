<div class="w3-content w3-border-bottom">
	<h1 class="w3-center">Using a Gameboy for AI Development</h1> 
	<p>
	I needed to do a semester project for my AI class but I also wanted to do something with the Gameboy emulator that I was working on at the time so I had the bright idea to create an AI that can play the Gameboy. My group partner Michael Knight and I wanted to go all out and create the hardest AI that we were able to find. This is what we turned in at the end:
	</p>
	<br><br>
</div>

<div class="w3-content w3-border-bottom">
	<p>
	Whenever someone wants to test out some idea for an AI, they first have to create an environment for the AI to be in. This is because each AI is deferent so it’s hard to use the same environment multiple times so why let all of that hard work go to waste?
	</p>
	<p>
	Nintendo's Gameboy is a handheld gaming system that was released in 1989. Over its lifetime, a staggering 1048 games were released for it. Because of its popularity and open documentation, emulation of it has become a standard exercise for anyone interested in emulation.
	</p>
	<p>
	Would using one of those Gameboy games on an emulator be a viable method of speeding up development time by removing the need to create a new environment each time?
	</p>
	<p>
	With the proposed notion of using an environment from one of these games, the versatility created from that amount of games should allow researchers to create a large variety of AI with the environmental data. 
	</p>
	<p>
	Without having to worry about an environment it will give more time for the development of the AI in a fun way.
	</p>
</div>
<br>

<div class="w3-content w3-border-bottom">
	<h2 class="w3-center">The Emulator</h2> 
	<p>
	The first step in the project was to have an emulator provide the details for the environment. This was rather difficult considering no such emulator existed that met our specifications. So we made our own. 
	</p>
	<p>
	What makes our emulator deferent from the others?
	</p>
	
	<h3>Full RAM Access</h3> 
	<p>
	Having access to the emulated game in its entirety is very important because we wanted any AI to be able to use it. A deep learning neural network might use all the internal ram while an A* pathfinder might just use the video ram. Because we created the emulator, we are able to see if a memory location has been updated. This allows for much faster I/O. For example a user needs the video RAM he can first ask if it has changed from the last time the user asked for it.
	</p>
	<h3>Network Input and Output</h3> 
	<p>
	Moving the AI environment away from the AI will require some sort of communication connection between them. We decided on using a simple UDP protocol where the emulator will constantly wait for a command. It will not stream, so each task will require a new command.
	</p>
	<br>
	<p>
	The emulator was made to be able to add commands easily. This has allowed us to do allot of the work on the emulator side without having to transfer a lot of information. The first four commands are just that, it was tedious working with the screen and the buttons until those commands where added.
	</p>
</div>

<div class="w3-content w3-border-bottom">
	<h2 class="w3-center">Research Methods</h2> 
	<p>
	We needed to test whether or not it would be viable and efficient for a Gameboy to provide the environment for an AI. For this task we decided to use two completely deferent AI methods for the same environment. That environment needed to be game that was simple and recognizable. Tetris, met those requirements.
	</p>
	
	<h3>Classic Tetris AI</h3> 
	<p>
	AI for Tetris has been an interesting computer science project for some time. There are many deferent strategies on the proper way of playing the game, in turn each programmer decides on a deferent AI method. The strategy we decided on was to make an AI rank every possible location and use the best rank as its next move. 
	</p>
	<p>
	The moves are ranked by:
	</p>
	<ul>
		<li>The height of the move</li>
		<li>Each row that will be cleared</li>
		<li>How many holes that will be created</li>
	</ul>
	<p>
	At First we made row clearing worth a lot of points but quickly found that it did not get very far into the game. This was because large holes formed resulting in a steady increase in height. To combat this, we made hole elimination and height control worth a lot more than if a move would cause a row to be cleared. That improvement had the effect of making the AI appear to be planning for the next move and on average, outperforming a human.
	</p>
	
	
	<h3>Network Input and Output</h3> 
	<p>
	Having completed a simple AI, something more advanced was necessary to prove our hypotheses. Instead of gradually increasing the complexity of the AI, we used Neuro Evolution of Augmenting Topologies (NEAT) because it’s the most advanced AI that we know of. 
	</p>
	<p>
	NEAT is good for:
	</p>
	<ul>
		<li>Looking at a lot of data</li>
		<li>Finding the useful parts of that data</li>
		<li>Doing a lot of work in very little time</li>
		<li>Expandable for many deferent games</li>
	</ul>
	<p>
	What makes it so complex is that it starts with a very small and random neural network then uses genetic algorithms to advance over many generations and species.
	</p>
	
	<h3>Conclusion</h3> 
	<p>
	We found working with the emulator became an easy and enjoyable process by taking away the need to create our own environment. It has considerably sped up development for the AI methods that where implemented. With more advanced emulators, the proposed idea of using games for research can be expanded. 
	</p>
</div>